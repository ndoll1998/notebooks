{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up\n",
    "n = 1024\n",
    "a_shape = (n, n)\n",
    "b_shape = (n, n)\n",
    "dtype = np.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.2 ms ± 1.17 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "a = np.random.uniform(-1, 1, size=a_shape).astype(dtype)\n",
    "b = np.random.uniform(-1, 1, size=b_shape).astype(dtype)\n",
    "o = np.empty((a_shape[0], b_shape[1]), dtype=dtype)\n",
    "\n",
    "%timeit c = np.dot(a, b, out=o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCL Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<pyopencl.Context at 0x26c62833800 on <pyopencl.Device 'GeForce GPU' on 'NVIDIA CUDA' at 0x26c632950b0>>,\n",
       " <pyopencl._cl.CommandQueue at 0x26c64190d08>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyopencl as cl\n",
    "ctx = cl.create_some_context()\n",
    "queue = cl.CommandQueue(ctx)\n",
    "ctx, queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<pyopencl._cl.Buffer at 0x26c641bdfa8>,\n",
       " <pyopencl._cl.Buffer at 0x26c64190ac8>,\n",
       " <pyopencl._cl.Buffer at 0x26c641907c8>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create inputs\n",
    "a = np.random.uniform(-1, 1, size=a_shape).astype(dtype)\n",
    "b = np.random.uniform(-1, 1, size=b_shape).astype(dtype)\n",
    "a_buf = cl.Buffer(ctx, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=a)\n",
    "b_buf = cl.Buffer(ctx, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=b)\n",
    "# create output buffer\n",
    "o = np.empty((a_shape[0], b_shape[1]), dtype=dtype)\n",
    "o_buf = cl.Buffer(ctx, cl.mem_flags.READ_WRITE, size=o.dtype.itemsize * a.shape[0] * b.shape[1])\n",
    "a_buf, b_buf, o_buf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCL Naive\n",
    "Unbelievably slow (5x slower than numpy wtf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"\"\"\n",
    "// First naive implementation\n",
    "__kernel void myGEMM1(const int M, const int N, const int K,\n",
    "                      const __global float* A,\n",
    "                      const __global float* B,\n",
    "                      __global float* C) {\n",
    "    \n",
    "    // Thread identifiers\n",
    "    const int globalRow = get_global_id(0); // Row ID of C (0..M)\n",
    "    const int globalCol = get_global_id(1); // Col ID of C (0..N)\n",
    " \n",
    "    // Compute a single element (loop over K)\n",
    "    float acc = 0.0f;\n",
    "    for (int k=0; k<K; k++) {\n",
    "        acc += A[k*M + globalRow] * B[globalCol*K + k];\n",
    "    }\n",
    " \n",
    "    // Store the result\n",
    "    C[globalCol*M + globalRow] = acc;\n",
    "}\n",
    "\"\"\"\n",
    "prg = cl.Program(ctx, source).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0065565286, 8.010864e-05)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m, n, k = a_shape[0], b_shape[1], b_shape[0]\n",
    "# check correctness\n",
    "prg.myGEMM1(queue, o.shape, None, np.int32(m), np.int32(n), np.int32(k), b_buf, a_buf, o_buf)\n",
    "cl.enqueue_copy(queue, o, o_buf)\n",
    "queue.flush()\n",
    "\n",
    "d = np.abs(o - (a @ b))\n",
    "np.linalg.norm(d), np.max(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ms ± 58.6 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "# timeit\n",
    "def matmul_opencl():\n",
    "    prg.myGEMM1(queue, o.shape, None, np.int32(m), np.int32(n), np.int32(k), b_buf, a_buf, o_buf)\n",
    "    queue.finish()\n",
    "matmul_opencl()\n",
    "\n",
    "%timeit -n 100 matmul_opencl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCL using local Blocks\n",
    "Pretty much as fast as numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"\"\"\n",
    "// from: https://github.com/sschaetz/nvidia-opencl-examples/blob/master/OpenCL/src/oclMultiThreads/matrixMul.cl\n",
    "\n",
    "#define BLOCK_SIZE 16\n",
    "#define AS(i, j) As[j + i * BLOCK_SIZE]\n",
    "#define BS(i, j) Bs[j + i * BLOCK_SIZE]\n",
    "\n",
    "///////////////////////////////////////////////////////////////////////////////\n",
    "//! Matrix multiplication on the device: C = A * B\n",
    "//! uiWA is A's width and uiWB is B's width\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "__kernel void\n",
    "matrixMul( __global float* C, __global float* A, __global float* B, int uiWA, int uiWB)\n",
    "{\n",
    "\n",
    "    // allocate local memory\n",
    "    __local float As[BLOCK_SIZE * BLOCK_SIZE];\n",
    "    __local float Bs[BLOCK_SIZE * BLOCK_SIZE];\n",
    "\n",
    "    // Block index\n",
    "    int bx = get_group_id(0);\n",
    "    int by = get_group_id(1);\n",
    "\n",
    "    // Thread index\n",
    "    int tx = get_local_id(0);\n",
    "    int ty = get_local_id(1);\n",
    "\n",
    "    // Index of the first sub-matrix of A processed by the block\n",
    "    int aBegin = uiWA * BLOCK_SIZE * by;\n",
    "\n",
    "    // Index of the last sub-matrix of A processed by the block\n",
    "    int aEnd   = aBegin + uiWA - 1;\n",
    "\n",
    "    // Step size used to iterate through the sub-matrices of A\n",
    "    int aStep  = BLOCK_SIZE;\n",
    "\n",
    "    // Index of the first sub-matrix of B processed by the block\n",
    "    int bBegin = BLOCK_SIZE * bx;\n",
    "\n",
    "    // Step size used to iterate through the sub-matrices of B\n",
    "    int bStep  = BLOCK_SIZE * uiWB;\n",
    "\n",
    "    // Csub is used to store the element of the block sub-matrix\n",
    "    // that is computed by the thread\n",
    "    float Csub = 0.0f;\n",
    "\n",
    "    // Loop over all the sub-matrices of A and B\n",
    "    // required to compute the block sub-matrix\n",
    "    for (int a = aBegin, b = bBegin;\n",
    "             a <= aEnd;\n",
    "             a += aStep, b += bStep) {\n",
    "\n",
    "        // Load the matrices from device memory\n",
    "        // to shared memory; each thread loads\n",
    "        // one element of each matrix\n",
    "        AS(ty, tx) = A[a + uiWA * ty + tx];\n",
    "        BS(ty, tx) = B[b + uiWB * ty + tx];\n",
    "\t\n",
    "        // Synchronize to make sure the matrices are loaded\n",
    "        barrier(CLK_LOCAL_MEM_FENCE);\n",
    "\n",
    "        // Multiply the two matrices together;\n",
    "        // each thread computes one element\n",
    "        // of the block sub-matrix        \n",
    "        #pragma unroll\n",
    "        for (int k = 0; k < BLOCK_SIZE; ++k)\n",
    "            Csub += AS(ty, k) * BS(k, tx);\n",
    "\n",
    "        // Synchronize to make sure that the preceding\n",
    "        // computation is done before loading two new\n",
    "        // sub-matrices of A and B in the next iteration\n",
    "        barrier(CLK_LOCAL_MEM_FENCE);\n",
    "    }\n",
    "\n",
    "    // Write the block sub-matrix to device memory;\n",
    "    // each thread writes one element\n",
    "    C[get_global_id(1) * get_global_size(0) + get_global_id(0)] = Csub;\n",
    "\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "prg = cl.Program(ctx, source).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0065565286, 8.010864e-05)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check correctness\n",
    "prg.matrixMul(queue, o.shape, [16, 16], o_buf, a_buf, b_buf, np.int32(a_shape[1]), np.int32(b_shape[1]))\n",
    "cl.enqueue_copy(queue, o, o_buf)\n",
    "queue.flush()\n",
    "\n",
    "d = np.abs(o - (a @ b))\n",
    "np.linalg.norm(d), np.max(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 ms ± 35.2 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "# timeit\n",
    "def matmul_opencl():\n",
    "    prg.matrixMul(queue, o.shape, [16, 16], o_buf, a_buf, b_buf, np.int32(a_shape[1]), np.int32(b_shape[1]))\n",
    "    queue.finish()\n",
    "matmul_opencl()\n",
    "\n",
    "%timeit -n 100 matmul_opencl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCL using Blocks and Registers\n",
    "Finally something that beats numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"\"\"\n",
    "// from: https://cnugteren.github.io/tutorial/pages/page8.html\n",
    "\n",
    "#define TSM 128                // The tile-size in dimension M\n",
    "#define TSN 128                // The tile-size in dimension N\n",
    "#define TSK 16                 // The tile-size in dimension K\n",
    "#define WPTM 8                 // The work-per-thread in dimension M\n",
    "#define WPTN 8                 // The work-per-thread in dimension N\n",
    "#define RTSM (TSM/WPTM)        // The reduced tile-size in dimension M\n",
    "#define RTSN (TSN/WPTN)        // The reduced tile-size in dimension N\n",
    "#define LPTA ((TSK*TSM)/(RTSM*RTSN)) // Loads-per-thread for A\n",
    "#define LPTB ((TSK*TSN)/(RTSM*RTSN)) // Loads-per-thread for B\n",
    "\n",
    "// Use 2D register blocking (further increase in work per thread)\n",
    "__kernel void myGEMM6(const int M, const int N, const int K,\n",
    "                      const __global float* A,\n",
    "                      const __global float* B,\n",
    "                      __global float* C) {\n",
    "    \n",
    "    // Thread identifiers\n",
    "    const int tidm = get_local_id(0); // Local row ID (max: TSM/WPTM)\n",
    "    const int tidn = get_local_id(1); // Local col ID (max: TSN/WPTN)\n",
    "    const int offsetM = TSM*get_group_id(0); // Work-group offset\n",
    "    const int offsetN = TSN*get_group_id(1); // Work-group offset\n",
    " \n",
    "    // Local memory to fit a tile of A and B\n",
    "    __local float Asub[TSK][TSM];\n",
    "    __local float Bsub[TSN][TSK];\n",
    " \n",
    "    // Allocate register space\n",
    "    float Areg;\n",
    "    float Breg[WPTN];\n",
    "    float acc[WPTM][WPTN];\n",
    " \n",
    "    // Initialise the accumulation registers\n",
    "    for (int wm=0; wm<WPTM; wm++) {\n",
    "        for (int wn=0; wn<WPTN; wn++) {\n",
    "            acc[wm][wn] = 0.0f;\n",
    "        }\n",
    "    }\n",
    "        \n",
    "    // Loop over all tiles\n",
    "    int numTiles = K/TSK;\n",
    "    for (int t=0; t<numTiles; t++) {\n",
    " \n",
    "        // Load one tile of A and B into local memory\n",
    "        for (int la=0; la<LPTA; la++) {\n",
    "            int tid = tidn*RTSM + tidm;\n",
    "            int id = la*RTSN*RTSM + tid;\n",
    "            int row = id % TSM;\n",
    "            int col = id / TSM;\n",
    "            int tiledIndex = TSK*t + col;\n",
    "            Asub[col][row] = A[tiledIndex*M + offsetM + row];\n",
    "            Bsub[row][col] = B[tiledIndex*N + offsetN + row];\n",
    "            // use transposed matrix B\n",
    "            // Bsub[row][col] = B[tiledIndex + (offsetN + row) * K];\n",
    "        }\n",
    "        \n",
    "        // Synchronise to make sure the tile is loaded\n",
    "        barrier(CLK_LOCAL_MEM_FENCE);\n",
    " \n",
    "        // Loop over the values of a single tile\n",
    "        for (int k=0; k<TSK; k++) {\n",
    " \n",
    "            // Cache the values of Bsub in registers\n",
    "            for (int wn=0; wn<WPTN; wn++) {\n",
    "                int col = tidn + wn*RTSN;\n",
    "                Breg[wn] = Bsub[col][k];\n",
    "            }\n",
    " \n",
    "            // Perform the computation\n",
    "            for (int wm=0; wm<WPTM; wm++) {\n",
    "                int row = tidm + wm*RTSM;\n",
    "                Areg = Asub[k][row];\n",
    "                for (int wn=0; wn<WPTN; wn++) {\n",
    "                    acc[wm][wn] += Areg * Breg[wn];\n",
    "                }\n",
    "            }\n",
    "        }\n",
    " \n",
    "        // Synchronise before loading the next tile\n",
    "        barrier(CLK_LOCAL_MEM_FENCE);\n",
    "    }\n",
    " \n",
    "    // Store the final results in C\n",
    "    for (int wm=0; wm<WPTM; wm++) {\n",
    "        int globalRow = offsetM + tidm + wm*RTSM;\n",
    "        for (int wn=0; wn<WPTN; wn++) {\n",
    "            int globalCol = offsetN + tidn + wn*RTSN;\n",
    "            C[globalCol*M + globalRow] = acc[wm][wn];\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "prg = cl.Program(ctx, source).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.00655901, 8.010864e-05)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m, n, k = a_shape[0], b_shape[1], b_shape[0]\n",
    "\n",
    "g_shape = (m//8, n//8)\n",
    "l_shape = (128//8, 128//8)\n",
    "\n",
    "# check correctness - notice that a and b positions are swapped\n",
    "prg.myGEMM6(queue, g_shape, l_shape, np.int32(m), np.int32(n), np.int32(k), b_buf, a_buf, o_buf)\n",
    "cl.enqueue_copy(queue, o, o_buf)\n",
    "queue.flush()\n",
    "\n",
    "# optimized memory accesses -> weird transposition of matrices\n",
    "d = np.abs(o - (a.T @ b))  # this is faster because ordered memory accesses (~5.86ms)\n",
    "# d = np.abs(o - (a @ b))      # when b is transposed in opencl code (~6.7ms)\n",
    "np.linalg.norm(d), np.max(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.87 ms ± 68.4 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "# timeit\n",
    "def matmul_opencl():\n",
    "    prg.myGEMM6(queue, g_shape, l_shape, np.int32(m), np.int32(n), np.int32(k), b_buf, a_buf, o_buf)\n",
    "    queue.finish()\n",
    "matmul_opencl()\n",
    "\n",
    "%timeit -n 100 matmul_opencl()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
